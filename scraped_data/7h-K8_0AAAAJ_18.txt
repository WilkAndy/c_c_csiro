{"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A framework for benchmarking land models", "pub_year": 2012, "citation": "Biogeosciences 9 (10), 3857-3874, 2012", "author": "YQ Luo and James T Randerson and G Abramowitz and C Bacour and E Blyth and Nuno Carvalhais and Philippe Ciais and Daniela Dalmonech and Joshua B Fisher and Rosie Fisher and P Friedlingstein and Kathy Hibbard and F Hoffman and Deborah Huntzinger and Chris D Jones and C Koven and D Lawrence and DJ Li and Miguel Mahecha and SL Niu and R Norby and SL Piao and X Qi and Philippe Peylin and I Collin Prentice and William Riley and Markus Reichstein and C Schwalm and YP Wang and JY Xia and S\u00f6nke Zaehle and XH Zhou", "journal": "Biogeosciences", "volume": "9", "number": "10", "pages": "3857-3874", "publisher": "Copernicus Publications", "abstract": "Land models, which have been developed by the modeling community in the past few decades to predict future states of ecosystems and climate, have to be critically evaluated for their performance skills of simulating ecosystem responses and feedback to climate change. Benchmarking is an emerging procedure to measure performance of models against a set of defined standards. This paper proposes a benchmarking framework for evaluation of land model performances and, meanwhile, highlights major challenges at this infant stage of benchmark analysis. The framework includes (1) targeted aspects of model performance to be evaluated, (2) a set of benchmarks as defined references to test model performance, (3) metrics to measure and compare performance skills among models so as to identify model strengths and deficiencies, and (4) model improvement. Land models are required to simulate exchange of water, energy, carbon and sometimes other trace gases between the atmosphere and land surface, and should be evaluated for their simulations of biophysical processes, biogeochemical cycles, and vegetation dynamics in response to climate change across broad temporal and spatial scales. Thus, one major challenge is to select and define a limited number of benchmarks to effectively evaluate land model performance. The second challenge is to develop metrics of measuring mismatches between models and benchmarks. The metrics may include (1) a priori thresholds of acceptable model performance and (2) a scoring system to combine data\u2013model mismatches for various processes at different temporal and spatial scales \u2026"}, "filled": true, "author_pub_id": "7h-K8_0AAAAJ:j3f4tGmQtD8C", "num_citations": 288, "citedby_url": "/scholar?hl=en&cites=12699882678074372987", "cites_id": ["12699882678074372987"], "pub_url": "https://bg.copernicus.org/articles/9/3857/2012/", "url_related_articles": "/scholar?oi=bibs&hl=en&oe=ASCII&q=related:e3PCQwIMP7AJ:scholar.google.com/", "cites_per_year": {"2011": 1, "2012": 1, "2013": 25, "2014": 25, "2015": 38, "2016": 38, "2017": 37, "2018": 33, "2019": 25, "2020": 17, "2021": 23, "2022": 20, "2023": 5}}