{"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Defending against adversarial attack towards deep neural networks via collaborative multi-task training", "pub_year": 2020, "citation": "IEEE Transactions on Dependable and Secure Computing 19 (2), 953-965, 2020", "author": "Derui Wang and Chaoran Li and Sheng Wen and Surya Nepal and Yang Xiang", "journal": "IEEE Transactions on Dependable and Secure Computing", "volume": "19", "number": "2", "pages": "953-965", "publisher": "IEEE", "abstract": "Deep neural networks (DNNs) are known to be vulnerable to adversarial examples which contain human-imperceptible perturbations. A series of defending methods, either proactive defence or reactive defence, have been proposed in the recent years. However, most of the methods can only handle specific attacks. For example, proactive defending methods are invalid against grey-box or white-box attacks, while reactive defending methods are challenged by low-distortion adversarial examples or transferring adversarial examples. This becomes a critical problem since a defender usually does not have the type of attack as  a priori  knowledge. Moreover, existing two-pronged defences (e.g., MagNet), which take advantage of both proactive and reactive methods, have been reported as broken under transferring attacks. To address this problem, this article proposed a novel defensive framework based on \u2026"}, "filled": true, "author_pub_id": "ge6zzwIAAAAJ:prdVHNxh-e8C", "num_citations": 22, "citedby_url": "/scholar?hl=en&cites=13570702962261880515", "cites_id": ["13570702962261880515"], "pub_url": "https://ieeexplore.ieee.org/abstract/document/9159878/", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:w-71iXHSVLwJ:scholar.google.com/", "cites_per_year": {"2020": 1, "2021": 8, "2022": 10, "2023": 3}}