{"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Token-modification adversarial attacks for natural language processing: A survey", "pub_year": 2021, "citation": "arXiv preprint arXiv:2103.00676, 2021", "author": "Tom Roth and Yansong Gao and Alsharif Abuadbba and Surya Nepal and Wei Liu", "journal": "arXiv preprint arXiv:2103.00676", "abstract": "There are now many adversarial attacks for natural language processing systems. Of these, a vast majority achieve success by modifying individual document tokens, which we call here a \\textit{token-modification} attack. Each token-modification attack is defined by a specific combination of fundamental \\textit{components}, such as a constraint on the adversary or a particular search algorithm. Motivated by this observation, we survey existing token-modification attacks and extract the components of each. We use an attack-independent framework to structure our survey which results in an effective categorisation of the field and an easy comparison of components. We hope this survey will guide new researchers to this field and spark further research into the individual attack components."}, "filled": true, "author_pub_id": "ge6zzwIAAAAJ:G1UMdFYMoxkC", "num_citations": 7, "citedby_url": "/scholar?hl=en&cites=16379187363722901045", "cites_id": ["16379187363722901045"], "pub_url": "https://arxiv.org/abs/2103.00676", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:NTZFbCCQTuMJ:scholar.google.com/", "cites_per_year": {"2021": 1, "2022": 4, "2023": 2}}