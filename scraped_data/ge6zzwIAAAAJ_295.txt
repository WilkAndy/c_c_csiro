{"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DeepiSign: Invisible fragile watermark to protect the integrity and authenticity of CNN", "pub_year": 2021, "citation": "Proceedings of the 36th Annual ACM Symposium on Applied Computing, 952-959, 2021", "author": "Alsharif Abuadbba and Hyoungshick Kim and Surya Nepal", "pages": "952-959", "abstract": "Convolutional Neural Networks (CNNs) deployed in real-life applications such as autonomous vehicles have shown to be vulnerable to manipulation attacks, such as poisoning attacks and fine-tuning. Hence, it is essential to ensure the integrity and authenticity of CNNs because compromised models can produce incorrect outputs and behave maliciously. In this paper, we propose a self-contained tamper-proofing method, called DeepiSign, to ensure the integrity and authenticity of CNN models against such manipulation attacks. DeepiSign applies the idea of fragile invisible watermarking to securely embed a secret and its hash value into a CNN model. To verify the integrity and authenticity of the model, we retrieve the secret from the model, compute the hash value of the secret, and compare it with the embedded hash value. To minimize the effects of the embedded secret on the CNN model, we use a wavelet \u2026"}, "filled": true, "author_pub_id": "ge6zzwIAAAAJ:__bU50VfleQC", "num_citations": 5, "citedby_url": "/scholar?hl=en&cites=7435286019247392742", "cites_id": ["7435286019247392742"], "pub_url": "https://dl.acm.org/doi/abs/10.1145/3412841.3441970", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:5kernD1xL2cJ:scholar.google.com/", "cites_per_year": {"2022": 4, "2023": 1}}