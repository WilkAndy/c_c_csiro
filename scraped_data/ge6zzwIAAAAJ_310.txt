{"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MACAB: Model-Agnostic Clean-Annotation Backdoor to Object Detection with Natural Trigger in Real-World", "pub_year": 2022, "citation": "arXiv preprint arXiv:2209.02339, 2022", "author": "Hua Ma and Yinshan Li and Yansong Gao and Zhi Zhang and Alsharif Abuadbba and Anmin Fu and Said F Al-Sarawi and Nepal Surya and Derek Abbott", "journal": "arXiv preprint arXiv:2209.02339", "abstract": "Object detection is the foundation of various critical computer-vision tasks such as segmentation, object tracking, and event detection. To train an object detector with satisfactory accuracy, a large amount of data is required. However, due to the intensive workforce involved with annotating large datasets, such a data curation task is often outsourced to a third party or relied on volunteers. This work reveals severe vulnerabilities of such data curation pipeline. We propose MACAB that crafts clean-annotated images to stealthily implant the backdoor into the object detectors trained on them even when the data curator can manually audit the images. We observe that the backdoor effect of both misclassification and the cloaking are robustly achieved in the wild when the backdoor is activated with inconspicuously natural physical triggers. Backdooring non-classification object detection with clean-annotation is challenging compared to backdooring existing image classification tasks with clean-label, owing to the complexity of having multiple objects within each frame, including victim and non-victim objects. The efficacy of the MACAB is ensured by constructively i abusing the image-scaling function used by the deep learning framework, ii incorporating the proposed adversarial clean image replica technique, and iii combining poison data selection criteria given constrained attacking budget. Extensive experiments demonstrate that MACAB exhibits more than 90% attack success rate under various real-world scenes. This includes both cloaking and misclassification backdoor effect even restricted with a small attack budget. The poisoned samples cannot \u2026"}, "filled": true, "author_pub_id": "ge6zzwIAAAAJ:I8rxH6phXEkC", "num_citations": 4, "citedby_url": "/scholar?hl=en&cites=8539797025377395143", "cites_id": ["8539797025377395143"], "pub_url": "https://arxiv.org/abs/2209.02339", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:x6GOFyZ0g3YJ:scholar.google.com/", "cites_per_year": {"2022": 2, "2023": 2}}