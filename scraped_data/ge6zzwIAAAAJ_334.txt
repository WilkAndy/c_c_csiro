{"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Transformer-Based Language Models for Software Vulnerability Detection", "pub_year": 2022, "citation": "Proceedings of the 38th Annual Computer Security Applications Conference \u2026, 2022", "author": "Chandra Thapa and Seung Ick Jang and Muhammad Ejaz Ahmed and Seyit Camtepe and Josef Pieprzyk and Surya Nepal", "pages": "481-496", "abstract": " The large transformer-based language models demonstrate excellent performance in natural language processing. By considering the transferability of the knowledge gained by these models in one domain to other related domains, and the closeness of natural languages to high-level programming languages, such as C/C++, this work studies how to leverage (large) transformer-based language models in detecting software vulnerabilities and how good are these models for vulnerability detection tasks. In this regard, firstly, we present a systematic (cohesive) framework that details source code translation, model preparation, and inference. Then, we perform an empirical analysis of software vulnerability datasets of C/C++ source codes having multiple vulnerabilities corresponding to the library function call, pointer usage, array usage, and arithmetic expression. Our empirical results demonstrate the good \u2026"}, "filled": true, "author_pub_id": "ge6zzwIAAAAJ:ifOnle78iJkC", "num_citations": 3, "citedby_url": "/scholar?hl=en&cites=7671092132226688187", "cites_id": ["7671092132226688187"], "pub_url": "https://dl.acm.org/doi/abs/10.1145/3564625.3567985", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:u2SqrKYxdWoJ:scholar.google.com/", "cites_per_year": {"2022": 1, "2023": 2}}