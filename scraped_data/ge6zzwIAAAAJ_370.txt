{"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Local differential privacy for federated learning in industrial settings", "pub_year": 2022, "citation": "arXiv preprint arXiv:2202.06053, 2022", "author": "MAP Chamikara and Dongxi Liu and Seyit Camtepe and Surya Nepal and Marthie Grobler and Peter Bertok and Ibrahim Khalil", "journal": "arXiv preprint arXiv:2202.06053", "abstract": "Federated learning (FL) is a collaborative learning approach that has gained much attention due to its inherent privacy preservation capabilities. However, advanced adversarial attacks such as membership inference and model memorization can still make FL vulnerable and potentially leak sensitive private data. Literature shows a few attempts to alleviate this problem by using global (GDP) and local differential privacy (LDP). Compared to GDP, LDP approaches are gaining more popularity due to stronger privacy notions and native support for data distribution. However, DP approaches assume that the server that aggregates the models, to be honest (run the FL protocol honestly) or semi-honest (run the FL protocol honestly while also trying to learn as much information possible), making such approaches unreliable for real-world settings. In real-world industrial environments (e.g. healthcare), the distributed entities (e.g. hospitals) are already composed of locally running machine learning models (e.g. high-performing deep neural networks on local health records). Existing approaches do not provide a scalable mechanism to utilize such settings for privacy-preserving FL. This paper proposes a new local differentially private FL (named LDPFL) protocol for industrial settings. LDPFL avoids the requirement of an honest or a semi-honest server and provides better performance while enforcing stronger privacy levels compared to existing approaches. Our experimental evaluation of LDPFL shows high FL model performance (up to ~98%) under a small privacy budget (e.g. epsilon = 0.5) in comparison to existing methods."}, "filled": true, "author_pub_id": "ge6zzwIAAAAJ:4e5Qn2KL_jwC", "num_citations": 2, "citedby_url": "/scholar?hl=en&cites=9497054248744537203", "cites_id": ["9497054248744537203"], "pub_url": "https://arxiv.org/abs/2202.06053", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:c0wIjYVQzIMJ:scholar.google.com/", "cites_per_year": {"2022": 2}}