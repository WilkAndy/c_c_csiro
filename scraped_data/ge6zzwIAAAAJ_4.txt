{"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Strip: A defence against trojan attacks on deep neural networks", "pub_year": 2019, "citation": "Proceedings of the 35th Annual Computer Security Applications Conference \u2026, 2019", "author": "Yansong Gao and Change Xu and Derui Wang and Shiping Chen and Damith C Ranasinghe and Surya Nepal", "pages": "113-125", "abstract": "A recent trojan attack on deep neural network (DNN) models is one insidious variant of data poisoning attacks. Trojan attacks exploit an effective backdoor created in a DNN model by leveraging the difficulty in interpretability of the learned model to misclassify any inputs signed with the attacker's chosen trojan trigger. Since the trojan trigger is a secret guarded and exploited by the attacker, detecting such trojan inputs is a challenge, especially at run-time when models are in active operation. This work builds STRong Intentional Perturbation (STRIP) based run-time trojan attack detection system and focuses on vision system. We intentionally perturb the incoming input, for instance by superimposing various image patterns, and observe the randomness of predicted classes for perturbed inputs from a given deployed model---malicious or benign. A low entropy in predicted classes violates the input-dependence \u2026"}, "filled": true, "author_pub_id": "ge6zzwIAAAAJ:L1USKYWJimsC", "num_citations": 450, "citedby_url": "/scholar?hl=en&cites=7514776661877233139", "cites_id": ["7514776661877233139"], "pub_url": "https://dl.acm.org/doi/abs/10.1145/3359789.3359790", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:85WWGY_ZSWgJ:scholar.google.com/", "cites_per_year": {"2019": 7, "2020": 61, "2021": 115, "2022": 180, "2023": 87}}