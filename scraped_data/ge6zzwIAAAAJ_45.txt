{"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Daedalus: Breaking nonmaximum suppression in object detection via adversarial examples", "pub_year": 2021, "citation": "IEEE Transactions on Cybernetics 52 (8), 7427-7440, 2021", "author": "Derui Wang and Chaoran Li and Sheng Wen and Qing-Long Han and Surya Nepal and Xiangyu Zhang and Yang Xiang", "journal": "IEEE Transactions on Cybernetics", "volume": "52", "number": "8", "pages": "7427-7440", "publisher": "IEEE", "abstract": "This article demonstrates that nonmaximum suppression (NMS), which is commonly used in object detection (OD) tasks to filter redundant detection results, is no longer secure. Considering that NMS has been an integral part of OD systems, thwarting the functionality of NMS can result in unexpected or even lethal consequences for such systems. In this article, an adversarial example attack that triggers malfunctioning of NMS in OD models is proposed. The attack, namely,  Daedalus , compresses the dimensions of detection boxes to evade NMS. As a result, the final detection output contains extremely dense false positives. This can be fatal for many OD applications, such as autonomous vehicles and surveillance systems. The attack can be generalized to different OD models, such that the attack cripples various OD applications. Furthermore, a way of crafting robust adversarial examples is developed by using an \u2026"}, "filled": true, "author_pub_id": "ge6zzwIAAAAJ:1taIhTC69MYC", "num_citations": 69, "citedby_url": "/scholar?hl=en&cites=17873889052023961916", "cites_id": ["17873889052023961916"], "pub_url": "https://ieeexplore.ieee.org/abstract/document/9313033/", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:PLmhlGTPDPgJ:scholar.google.com/", "cites_per_year": {"2020": 14, "2021": 10, "2022": 33, "2023": 8}}