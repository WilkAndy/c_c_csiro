{"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Backdoor attacks against transfer learning with pre-trained deep learning models", "pub_year": 2020, "citation": "IEEE Transactions on Services Computing 15 (3), 1526-1539, 2020", "author": "Shuo Wang and Surya Nepal and Carsten Rudolph and Marthie Grobler and Shangyu Chen and Tianle Chen", "journal": "IEEE Transactions on Services Computing", "volume": "15", "number": "3", "pages": "1526-1539", "publisher": "IEEE", "abstract": "Transfer learning provides an effective solution for feasibly and fast customize accurate  Student  models, by transferring the learned knowledge of pre-trained  Teacher  models over large datasets via fine-tuning. Many pre-trained Teacher models used in transfer learning are publicly available and maintained by public platforms, increasing their vulnerability to backdoor attacks. In this article, we demonstrate a backdoor threat to transfer learning tasks on both image and time-series data leveraging the knowledge of publicly accessible Teacher models, aimed at defeating three commonly adopted defenses:  pruning-based ,  retraining-based  and  input pre-processing-based defenses . Specifically, (  ) ranking-based selection mechanism to speed up the backdoor trigger generation and perturbation process while defeating  pruning-based  and/or  retraining-based defenses . (  ) autoencoder-powered trigger generation is \u2026"}, "filled": true, "author_pub_id": "ge6zzwIAAAAJ:eO3_k5sD8BwC", "num_citations": 65, "citedby_url": "/scholar?hl=en&cites=13911378731557408924", "cites_id": ["13911378731557408924"], "pub_url": "https://ieeexplore.ieee.org/abstract/document/9112322/", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:nFBnLkAlD8EJ:scholar.google.com/", "cites_per_year": {"2020": 5, "2021": 18, "2022": 32, "2023": 10}}