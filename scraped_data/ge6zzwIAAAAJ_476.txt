{"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Fingerprinting of DNN with Black-box Design and Verification", "pub_year": 2022, "citation": "arXiv preprint arXiv:2203.10902, 2022", "author": "Shuo Wang and Sharif Abuadbba and Sidharth Agarwal and Kristen Moore and Ruoxi Sun and Minhui Xue and Surya Nepal and Seyit Camtepe and Salil Kanhere", "journal": "arXiv preprint arXiv:2203.10902", "abstract": "Cloud-enabled Machine Learning as a Service (MLaaS) has shown enormous promise to transform how deep learning models are developed and deployed. Nonetheless, there is a potential risk associated with the use of such services since a malicious party can modify them to achieve an adverse result. Therefore, it is imperative for model owners, service providers, and end-users to verify whether the deployed model has not been tampered with or not. Such verification requires public verifiability (ie, fingerprinting patterns are available to all parties, including adversaries) and black-box access to the deployed model via APIs. Existing watermarking and fingerprinting approaches, however, require white-box knowledge (such as gradient) to design the fingerprinting and only support private verifiability, ie, verification by an honest party.In this paper, we describe a practical watermarking technique that enables black \u2026"}, "filled": true, "author_pub_id": "ge6zzwIAAAAJ:In6cVmBjs0IC", "num_citations": 0, "pub_url": "https://scholar.google.com/scholar?cluster=13399423815034054627&hl=en&oi=scholarr", "cites_per_year": {}}