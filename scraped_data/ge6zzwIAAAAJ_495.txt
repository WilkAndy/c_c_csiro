{"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adversarial Defense by Latent Style Transformations", "pub_year": 2020, "citation": "arXiv preprint arXiv:2006.09701, 2020", "author": "Shuo Wang and Surya Nepal and Marthie Grobler and Carsten Rudolph and Tianle Chen and Shangyu Chen", "journal": "arXiv preprint arXiv:2006.09701", "abstract": "Machine learning models have demonstrated vulnerability to adversarial attacks, more specifically misclassification of adversarial examples. In this paper, we investigate an attack-agnostic defense against adversarial attacks on high-resolution images by detecting suspicious inputs. The intuition behind our approach is that the essential characteristics of a normal image are generally consistent with non-essential style transformations, e.g., slightly changing the facial expression of human portraits. In contrast, adversarial examples are generally sensitive to such transformations. In our approach to detect adversarial instances, we propose an in\\underline{V}ertible \\underline{A}utoencoder based on the \\underline{S}tyleGAN2 generator via \\underline{A}dversarial training (VASA) to inverse images to disentangled latent codes that reveal hierarchical styles. We then build a set of edited copies with non-essential style transformations by performing latent shifting and reconstruction, based on the correspondences between latent codes and style transformations. The classification-based consistency of these edited copies is used to distinguish adversarial instances."}, "filled": true, "author_pub_id": "ge6zzwIAAAAJ:DyXnQzXoVgIC", "num_citations": 0, "pub_url": "https://arxiv.org/pdf/2006.09701", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:H_l3ou9UhIYJ:scholar.google.com/", "cites_per_year": {}}