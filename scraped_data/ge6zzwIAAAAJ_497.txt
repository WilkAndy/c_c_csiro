{"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A Defence Against Input-Agnostic Backdoor Attacks on Deep Neural Networks", "pub_year": 2020, "citation": "Information Systems Security: 16th International Conference, ICISS 2020 \u2026, 2020", "author": "Yansong Gao and Surya Nepal", "conference": "Information Systems Security: 16th International Conference, ICISS 2020, Jammu, India, December 16\u201320, 2020, Proceedings 16", "pages": "69-80", "publisher": "Springer International Publishing", "abstract": "Backdoor attacks insert hidden associations or triggers to the deep neural network (DNN) models to override correct inference such as classification. Such attacks perform maliciously according to the attacker-chosen target while behaving normally in the absence of the trigger. These attacks, though new, are rapidly evolving as a realistic attack, and could result in severe consequences, especially considering that backdoor attacks can be inserted in variety of real-world applications. This paper first provides a brief overview of backdoor attacks and then presents a countermeasure, STRong Intentional Perturbation (STRIP). STRIP intentionally perturbs the incoming input, for instance by superimposing various image patterns, and observes the randomness of predicted classes for perturbed inputs from a given deployed model \u2013 malicious or benign. STRIP fundamentally relies on the entropy in predicted classes; for \u2026"}, "filled": true, "author_pub_id": "ge6zzwIAAAAJ:L_l9e5I586QC", "num_citations": 0, "pub_url": "https://link.springer.com/chapter/10.1007/978-3-030-65610-2_4", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:1-YLwqepEnYJ:scholar.google.com/", "cites_per_year": {}}