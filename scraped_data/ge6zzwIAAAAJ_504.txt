{"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Defensive Collaborative Multi-task Training", "pub_year": 2018, "citation": "arXiv preprint arXiv:1803.05123, 2018", "author": "Derek Wang and Chaoran Li and Sheng Wen and Yang Xiang and Wanlei Zhou and Surya Nepal", "journal": "arXiv preprint arXiv:1803.05123", "abstract": "Deep neural network (DNNs) has shown impressive performance on hard perceptual problems. However, researchers found that DNN-based systems are vulnerable to adversarial examples which contain specially crafted humans-imperceptible perturbations. Such perturbations cause DNN-based systems to mis-classify the adversarial examples, with potentially disastrous consequences where safety or security is crucial. As a major security concern, state-ofthe-art attacks can still bypass the existing defensive methods. In this paper, we propose a novel defensive framework based on collaborative multi-task training to address the above problem. The proposed defence first incorporates specific label pairs into adversarial training process to enhance model robustness in blackbox setting. Then a novel collaborative multi-task training framework is proposed to construct a detector which identifies adversarial examples based on the pairwise relationship of the label pairs. The detector can identify and reject high confidence adversarial examples that bypass black-box defence. The model whose robustness has been enhanced work reciprocally with the detector on the false-negative adversarial examples. Importantly, the proposed collaborative architecture can prevent the adversary from finding valid adversarial examples in a nearly-white-box setting."}, "filled": true, "author_pub_id": "ge6zzwIAAAAJ:QUX0mv85b1cC", "num_citations": 0, "pub_url": "https://scholar.google.com/scholar?cluster=4518957562540922609&hl=en&oi=scholarr", "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:8RZR7vWPtj4J:scholar.google.com/", "cites_per_year": {}}